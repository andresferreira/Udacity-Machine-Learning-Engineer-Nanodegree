{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Q-learning\n",
    "#### Reference: http://mnemstudio.org/path-finding-q-learning-tutorial.htm\n",
    "\n",
    "Find a shortest path from Room 2 -> Outside(5) by Q-learning(not BFS!!!!!) \n",
    "![](./img/10_rooms.jpg \"map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a graph and rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/10_graph.jpg \"graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = [\n",
    "    [0, 0, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 1, 0, 1],\n",
    "    [0, 0, 0, 1, 0, 0],\n",
    "    [0, 1, 1, 0, 1, 0],\n",
    "    [1, 0, 0, 1, 0, 1],\n",
    "    [0, 1, 0, 0, 1, 1]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Reward](./img/10_rewards.jpg \"Reward\")\n",
    "![Reward matrix](./img/10_r_matrix.jpg \"Reward matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = [\n",
    "    [-1, -1, -1, -1, 0, -1],\n",
    "    [-1, -1, -1, 0, -1, 100],\n",
    "    [-1, -1, -1, 0, -1, -1],\n",
    "    [-1, 0, 0, -1, 0, -1],\n",
    "    [0, -1, -1, 0, -1, 100],\n",
    "    [-1, 0, -1, -1, 0, 100]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning\n",
    "- Set parameters: alpha, gamma, R...\n",
    "- Initialize matrix Q to zero.\n",
    "- Q-Learning Algo:\n",
    "```\n",
    "    For each episode\n",
    "        Select a random initial state.\n",
    "        While the goal state hasn't been reached.\n",
    "            - Select one among all possible actions for the current state.\n",
    "            - Using this possible action, consider going to the next state.\n",
    "            - Get maximum Q value for this next state based on all possible actions.\n",
    "            - Update Q: \n",
    "                Q(state, action) = \n",
    "                    (1-alpha)*Q(state, action) \n",
    "                    + alpha*(R(state, action) + Gamma * Max[Q(next state, all actions)])\n",
    "            - Set the next state as the current state.\n",
    "```\n",
    "- Algorithm to utilize the Q matrix\n",
    "```\n",
    "    1. Set current state = initial state.\n",
    "    2. From current state, find the action with the highest Q value.\n",
    "    3. Set current state = next state.\n",
    "    4. Repeat Steps 2 and 3 until current state = goal state.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_one_possible_action(cur_state):\n",
    "    # Get all possible actions\n",
    "    actions = []\n",
    "    for action in range(6):\n",
    "        if G[cur_state][action] != 0:\n",
    "            actions.append(action)\n",
    "    \n",
    "    # Choose 1 action randomly\n",
    "    return random.choice(actions)\n",
    "\n",
    "\n",
    "def get_max_val(next_state):\n",
    "    # Find max action\n",
    "    max_action_val = -999\n",
    "    for action in range(6):\n",
    "        if G[next_state][action] != 0:\n",
    "            max_action_val = max(max_action_val, Q[next_state][action])\n",
    "\n",
    "    return max_action_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 100.0, 0],\n",
       " [0, 0, 0, 50.0, 0, 200.0],\n",
       " [0, 0, 0, 50.0, 0, 0],\n",
       " [0, 100.0, 25.0, 0, 100.0, 0],\n",
       " [50.0, 0, 0, 50.0, 0, 200.0],\n",
       " [0, 100.0, 0, 0, 100.0, 200.0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.2\n",
    "gamma = 0.5\n",
    "states = [0,1,2,3,4,5]\n",
    "train_steps = 100\n",
    "\n",
    "# Init Q\n",
    "Q = [[0 for x in range(6)] for y in range(6)]\n",
    "\n",
    "\n",
    "for i in range(train_steps):\n",
    "    cur_state = random.choice(states)\n",
    "    for j in range(train_steps):\n",
    "        action = get_one_possible_action(cur_state)\n",
    "        next_state = action\n",
    "\n",
    "        max_val = get_max_val(next_state)\n",
    "        Q[cur_state][action] = (1 - alpha)*Q[cur_state][action] + alpha*(R[cur_state][action] + gamma * max_val)\n",
    "\n",
    "        cur_state = next_state\n",
    "\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_room(cur_room):\n",
    "    max_val = -999\n",
    "    next_room = -1\n",
    "    for room in range(6):\n",
    "        if Q[cur_room][room] > max_val:\n",
    "            max_val = Q[cur_room][room]\n",
    "            next_room = room\n",
    "    return next_room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 1, 5]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_room = 2\n",
    "goal_room = 5\n",
    "path = [init_room]\n",
    "\n",
    "cur_room = init_room\n",
    "for i in range(10):\n",
    "    if cur_room == goal_room:\n",
    "        break\n",
    "    \n",
    "    next_room = get_next_room(cur_room)\n",
    "    path.append(next_room)\n",
    "    cur_room = next_room\n",
    "\n",
    "path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
